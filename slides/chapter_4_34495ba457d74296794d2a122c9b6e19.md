---
title: 'Insert title here'
key: 34495ba457d74296794d2a122c9b6e19
---

## Numpy: Basic Statistics

```yaml
type: TitleSlide
key: 5d21c4b49f
```

`@lower_third`
name: Filip Schouwenaars
title: Instructor

`@script`
A typical first step in analyzing your data, is getting to know your data in the first place. For the Numpy arrays from before, this is pretty easy, because it isn't a lot of data. However, as a data scientist, you'll be crunching thousands, if not millions or billions of numbers.

Imagine you conduct a city-wide survey where you ask 5000 adults about their height and weight. You end up with something like this: a 2D numpy array, which I named np_city, that has 5000 rows, corresponding to the 5000 people, and two columns, corresponding to the height and the weight.

Simply staring at these numbers like a zombie won't give you any insights. What you can do, though, is generate summarizing statistics about your data. Aside from an efficient data structure for number crunching, it happens that Numpy is also good at doing these kinds of things.

For starters, you can try to find out the average height of these 5000 people, with Numpy's mean function. Because it's a function from the Numpy package, don't forget to start with np..

Of course, I first had to do a subsetting operation to get the height column from the 2D array. It appears that on average, people are 1-point-75 meters tall. What about the median height? This is the height of the middle person if you sort all persons from small to tall. Instead of writing complicated python code to figure this out, you can simply use Numpy's median function:

You can do similar things for the weight column in np_city. Often, these summarizing statistics will provide you with a "sanity check" of your data. If you end up with a average weight of 2000 kilograms, your measurements are most likely incorrect.

Apart from mean and median, there's also other functions, like corrcoeff to check if for example height and weight are correlated,

and std, for standard deviation.

Numpy also features more basic functions, such as sum and sort, which also exist in the basic Python distribution. However, the big difference here is speed. Because Numpy enforces a single data type in an array, it can drastically speed up the calculations.

Just a sidenote here: If you're wondering how I came up with the data in this video: I simulated it with Numpy functions! I sampled two random distributions 5000 times to create the height and weight arrays, and then used column_stack to paste them together as two columns. Another thing that Numpy can do!

Another great tool to get some sense of your data is to visualize it, but that's something for later. First, head over to the exercises to learn how to explore your Numpy arrays!

---

## Data analysis

```yaml
type: FullSlide
key: 32899f8a31
```

`@part1`
- Get to know your data{{1}}

- Little data -> simply look at it{{2}}

- Big data -> ?{{3}}

`@script`


---

## City-wide survey

```yaml
type: FullSlide
key: df02059657
```

`@part1`
```py
import numpy as np
np_city = ... # Implementation left out
np_city
```

```out
array([[  1.64,  71.78],
       [  1.37,  63.35],
       [  1.6 ,  55.09],
       ...,
       [  2.04,  74.85],
       [  2.04,  68.72],
       [  2.01,  73.57]])
```

`@script`


---

## Numpy

```yaml
type: FullSlide
key: d3c991b91f
```

`@part1`
```py
np.mean(np_city[:,0])
```

```out
1.7472
```

```py
np.median(np_city[:,0])
```

```out
1.75
```

```py
np.corrcoef(np_city[:,0], np_city[:,1])
```

```out
array([[ 1.     , -0.01802],
       [-0.01803,  1.     ]])
```

```py
np.std(np_city[:,0])
```

```out
0.1992
```

`@script`


---

## Generate data

```yaml
type: FullSlide
key: 0c27803967
```

`@part1`
- distribution mean

- number of samples


```py
height = np.round(np.random.normal(1.75, 0.20, 5000), 2)
```

`@script`


---

## Let's practice!

```yaml
type: FinalSlide
key: c4df18cfc1
```

`@script`
